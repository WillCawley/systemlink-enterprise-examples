{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Space Analysis Example\n",
    "\n",
    "This notebook will analyze the parametric data in a dataspace to calculate statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "Import Python modules for executing the notebook. The ni_data_space_analyzer is used for performing some of the standard analyses. Pandas is used for building and handling the data in the data space. Scrapbook is used for running notebooks and recording data for the SystemLink Notebook Execution Service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scrapbook as sb\n",
    "\n",
    "from ni_data_space_analyzer import DataSpaceAnalyzer\n",
    "from ni_data_space_analyzer.exception import DataSpaceAnalyzerError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom analysis \n",
    "\n",
    "Apart from the standard statistics, you can add custom analysis functions to compute additional statistics on the trace data. You can follow the following steps:\n",
    "\n",
    "- Add the custom analysis in [parameters cell](#parameters) output metadata (see commented lines in the [Metadata](#Metadata) section).\n",
    "- Add the custom analysis in supported analysis options (see commented lines in the [Supported analysis options](#supported-analysis-options) section).\n",
    "- Implement the custom analysis logic (see commented lines in the [Perform analysis](#Perform-analysis) section). A sample implementation is provided below for reference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "\n",
    "1. `trace_data` - Data from the traces plotted in the dataspace to be analyzed. It will be stored as notebook execution artifact.\n",
    "2. `analysis_options` - List of analysis to be performed against plotted traces in the dataspace.\n",
    "3. `workspace_id` - Workspace ID of the dataspace to be analyzed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "papermill": {
     "parameters": {
      "analysis_options": [],
      "trace_data": ""
     }
    },
    "slideshow": {
     "slide_type": ""
    },
    "systemlink": {
     "interfaces": [
      "ni-testmanagement"
     ],
     "outputs": [
      {
       "display_name": "Min",
       "id": "min",
       "type": "scalar"
      },
      {
       "display_name": "Max",
       "id": "max",
       "type": "scalar"
      },
      {
       "display_name": "Mean",
       "id": "mean",
       "type": "scalar"
      },
      {
       "display_name": "2 STD",
       "id": "2std",
       "type": "scalar"
      },
      {
       "display_name": "-2 STD",
       "id": "-2std",
       "type": "scalar"
      },
      {
       "display_name": "Moving Mean",
       "id": "moving_mean",
       "type": "vector"
      },
      {
       "display_name": "CP",
       "id": "cp",
       "type": "vector"
      },
      {
       "display_name": "CPK",
       "id": "cpk",
       "type": "vector"
      }
     ],
     "parameters": [
      {
       "display_name": "Trace data",
       "id": "trace_data",
       "type": "string"
      },
      {
       "display_name": "Analysis Options",
       "id": "analysis_options",
       "type": "string[]"
      }
     ],
     "version": 2
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "trace_data = {\"artifact_id\": \"<artifact_id>\"}\n",
    "analysis_options = []\n",
    "workspace_id = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "\n",
    "These are the parameters that the notebook expects to be passed in by SystemLink. For notebooks designed to be perform analysis inside a dataspace, must tag the cell with 'parameters' and at minimum specify the following in the cell metadata using the JupyterLab Property Inspector (double gear icon):\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"papermill\": {\n",
    "    \"parameters\": {\n",
    "      \"analysis_options\": [],\n",
    "      \"trace_data\": {\"artifact_id\": \"<artifact_id>\"},\n",
    "      \"workspace_id\": \"\"\n",
    "    }\n",
    "  },\n",
    "  \"systemlink\": {\n",
    "    \"interfaces\": [],\n",
    "    \"outputs\": [\n",
    "      {\n",
    "        \"display_name\": \"Min\",\n",
    "        \"id\": \"min\",\n",
    "        \"type\": \"scalar\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"Max\",\n",
    "        \"id\": \"max\",\n",
    "        \"type\": \"scalar\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"Mean\",\n",
    "        \"id\": \"mean\",\n",
    "        \"type\": \"scalar\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"2 STD\",\n",
    "        \"id\": \"2std\",\n",
    "        \"type\": \"scalar\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"-2 STD\",\n",
    "        \"id\": \"-2std\",\n",
    "        \"type\": \"scalar\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"Moving Mean\",\n",
    "        \"id\": \"moving_mean\",\n",
    "        \"type\": \"vector\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"CP\",\n",
    "        \"id\": \"cp\",\n",
    "        \"type\": \"vector\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"CPK\",\n",
    "        \"id\": \"cpk\",\n",
    "        \"type\": \"vector\"\n",
    "      },\n",
    "      // {\n",
    "      //   \"display_name\": \"Custom Analysis Scalar\",\n",
    "      //   \"id\": \"custom_analysis_scalar\",\n",
    "      //   \"type\": \"scalar\"\n",
    "      // },\n",
    "      // {\n",
    "      //   \"display_name\": \"Custom Analysis Vector\",\n",
    "      //   \"id\": \"custom_analysis_vector\",\n",
    "      //   \"type\": \"vector\"\n",
    "      // }\n",
    "    ],\n",
    "    \"parameters\": [\n",
    "      {\n",
    "        \"display_name\": \"Trace data\",\n",
    "        \"id\": \"trace_data\",\n",
    "        \"type\": \"dict[string, string]\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"Analysis Options\",\n",
    "        \"id\": \"analysis_options\",\n",
    "        \"type\": \"string[]\"\n",
    "      },\n",
    "      {\n",
    "        \"display_name\": \"Workspace ID\",\n",
    "        \"id\": \"workspace_id\",\n",
    "        \"type\": \"string\"\n",
    "      }\n",
    "    ],\n",
    "    \"version\": 2\n",
    "  },\n",
    "  \"tags\": [\"parameters\"]\n",
    "}\n",
    "````\n",
    "\n",
    "For more information on how parameterization works, review the [papermill documentation](https://papermill.readthedocs.io/en/latest/usage-parameterize.html#how-parameters-work).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supported analysis options\n",
    "\n",
    "1. Mean: The central value of the data set.\n",
    "2. 2 STD: Two standard deviations from the mean.\n",
    "3. -2 STD: Negative two standard deviations from the mean.\n",
    "4. Min: The minimum value in the data set.\n",
    "5. Max: The maximum value in the data set.\n",
    "6. Moving Mean: The central value of the most recent X data points.\n",
    "7. Cpk: The process capability index. Describes the ability of a process to provide output that will be within the required specifications consistently.\n",
    "8. Cp: The process capability. The process capability is a measure of the potential for a process to provide output that is within upper and lower specification limits.\n",
    "\n",
    "9. *(Optional) custom_analysis_scalar: Sample scalar custom analysis.*\n",
    "10. *(Optional) custom_analysis_vector: Sample vector custom analysis.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "supported_analysis = [\n",
    "    {\"id\": \"min\", \"type\": \"scalar\"},\n",
    "    {\"id\": \"max\", \"type\": \"scalar\"},\n",
    "    {\"id\": \"mean\", \"type\": \"scalar\"},\n",
    "    {\"id\": \"2std\", \"type\": \"scalar\"},\n",
    "    {\"id\": \"-2std\", \"type\": \"scalar\"},\n",
    "    {\"id\": \"moving_mean\", \"type\": \"vector\"},\n",
    "    {\"id\": \"cp\", \"type\": \"vector\"},\n",
    "    {\"id\": \"cpk\", \"type\": \"vector\"},\n",
    "    # {\"id\": \"custom_analysis_scalar\", \"type\": \"scalar\"},\n",
    "    # {\"id\": \"custom_analysis_vector\", \"type\": \"vector\"},\n",
    "]\n",
    "\n",
    "supported_analysis_options = list(map(lambda x: x[\"id\"], supported_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validate Analysis options\n",
    "\n",
    "It validates that the analysis options from execution input are in the list of analysis options the notebook supports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_analysis_options(analysis_options) -> None:\n",
    "    analysis_options = list(map(str.strip, analysis_options))\n",
    "\n",
    "    invalid_options = list(set(analysis_options) - set(supported_analysis_options))\n",
    "\n",
    "    if invalid_options:\n",
    "        raise DataSpaceAnalyzerError(\n",
    "            \"The analysis failed because the following options are not supported: {0}.\".format(\n",
    "                \", \".join(invalid_options)\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample custom analysis\n",
    "\n",
    "Sample implementation for scalar and vector custom analysis, and how it should be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_custom_analysis_scalar(trace_data_dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"Compute `custom_analysis_scalar` of the dataframe.\"\"\"\n",
    "    \n",
    "    # Perform actual custom_analysis_scalar\n",
    "    custom_analysis_scalar_sample_result = trace_data_dataframe['y'].describe()['count']\n",
    "    trace_data_dataframe['custom_analysis_scalar'] = custom_analysis_scalar_sample_result\n",
    "\n",
    "def compute_custom_analysis_vector(trace_data_dataframe: pd.DataFrame) -> None:\n",
    "    \"\"\"Compute `custom_analysis_vector` of the dataframe.\"\"\"\n",
    "\n",
    "    # Perform actual custom_analysis_vector\n",
    "    custom_analysis_vector_sample_result = trace_data_dataframe['y'].rolling(1).median()\n",
    "    trace_data_dataframe['custom_analysis_vector'] = custom_analysis_vector_sample_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform analysis\n",
    "\n",
    "By default the analysis results will be appended to original dataframe, and users can generate the analysis results using **generate_analysis_output** method inside **data_space_analyzer** for the given analysis options and supported analysis as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_analysis(trace_data_dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "    data_space_analyzer = DataSpaceAnalyzer(dataframe=trace_data_dataframe)\n",
    "\n",
    "    for option in analysis_options:\n",
    "        if option == \"min\":\n",
    "            data_space_analyzer.compute_min()\n",
    "        elif option == \"max\":\n",
    "            data_space_analyzer.compute_max()\n",
    "        elif option == \"mean\":\n",
    "            data_space_analyzer.compute_mean()\n",
    "        elif option == \"2std\":\n",
    "            data_space_analyzer.compute_2std()\n",
    "        elif option == \"-2std\":\n",
    "            data_space_analyzer.compute_negative_2std()\n",
    "        elif option == \"moving_mean\":\n",
    "            data_space_analyzer.compute_moving_mean()\n",
    "        elif option == \"cp\":\n",
    "            data_space_analyzer.compute_cp()\n",
    "        elif option == \"cpk\":\n",
    "            data_space_analyzer.compute_cpk()\n",
    "        # elif option == \"custom_analysis_scalar\":\n",
    "        #     compute_custom_analysis_scalar(trace_data_dataframe)\n",
    "        # elif option == \"custom_analysis_vector\":\n",
    "        #     compute_custom_analysis_vector(trace_data_dataframe)\n",
    "\n",
    "    return data_space_analyzer.generate_analysis_output(\n",
    "        analysis_options=analysis_options, supported_analysis=supported_analysis\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save analysis results\n",
    "\n",
    "Users can save the analysis results into an artifact using the **save_analysis** method within **data_space_analyzer**. The output will be an artifact ID, representing the compressed and stored analysis data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_options = list(map(str.lower, analysis_options))\n",
    "final_result = []\n",
    "\n",
    "try:\n",
    "    validate_analysis_options(analysis_options)\n",
    "    data_space_analyzer = DataSpaceAnalyzer(pd.DataFrame())\n",
    "    traces = data_space_analyzer.load_dataset(trace_data)\n",
    "\n",
    "    for trace in traces:\n",
    "        trace_data_name = trace[\"name\"]\n",
    "        trace_data_dataframe = trace[\"data\"]\n",
    "\n",
    "        analysis_results = perform_analysis(trace_data_dataframe)\n",
    "        \n",
    "        final_result.append({\"plot_label\": trace_data_name, \"data\": analysis_results})\n",
    "    \n",
    "    output_artifact_id = data_space_analyzer.save_analysis(workspace_id, final_result)\n",
    "\n",
    "except DataSpaceAnalyzerError as e:\n",
    "    raise Exception(e) from None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the result information so that SystemLink can access it\n",
    "\n",
    "SystemLink uses scrapbook to store result information from each notebook execution to display to the user in the Execution Details slide-out.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.glue(\"result\", output_artifact_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Output format\n",
    "\n",
    "```json\n",
    "{\n",
    "    output_artifact_id: \"ec25561d-6509-49e5-9a78-30e9752733fe\"\n",
    "}\n",
    "```\n",
    "\n",
    "`output_artifact_id` - The ID of the artifact file where the output data is compressed and stored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next Steps\n",
    "\n",
    "1. Publish this notebook to SystemLink by right-clicking it in the JupyterLab File Browser with the interface as Data Space Analysis.\n",
    "1. Manually Analyze the parametric data inside the dataspace by clicking analyze button.\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
